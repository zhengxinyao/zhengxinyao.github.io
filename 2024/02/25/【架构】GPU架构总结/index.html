<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>【架构】GPU架构总结 | Xinyao</title>
  <meta name="keywords" content=" GPU , 架构 ">
  <meta name="description" content="【架构】GPU架构总结 | Xinyao">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="description" content="勇攀高峰">
<meta property="og:type" content="website">
<meta property="og:title" content="tags">
<meta property="og:url" content="https://zhengxinyao.github.io/tags/index.html">
<meta property="og:site_name" content="Xinyao">
<meta property="og:description" content="勇攀高峰">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-02-07T15:59:52.000Z">
<meta property="article:modified_time" content="2024-02-07T15:59:52.773Z">
<meta property="article:author" content="zxy">
<meta name="twitter:card" content="summary">


<link rel="icon" href="/img/favicon.png">

<link href="/css/style.css?v=1.1.0" rel="stylesheet">

<link href="/css/hl_theme/atom-light.css?v=1.1.0" rel="stylesheet">

<link href="//cdn.jsdelivr.net/npm/animate.css@4.1.0/animate.min.css" rel="stylesheet">

<script src="//cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
<script src="/js/titleTip.js?v=1.1.0" ></script>

<script src="//cdn.jsdelivr.net/npm/highlightjs@9.16.2/highlight.pack.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>

<script src="//cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script>



<script src="//cdn.jsdelivr.net/npm/jquery.cookie@1.4.1/jquery.cookie.min.js" ></script>

<script src="/js/iconfont.js?v=1.1.0" ></script>

<meta name="generator" content="Hexo 7.1.1"></head>
<div style="display: none">
  <input class="theme_disqus_on" value="false">
  <input class="theme_preload_comment" value="">
  <input class="theme_blog_path" value="">
  <input id="theme_shortcut" value="true" />
  <input id="theme_highlight_on" value="true" />
  <input id="theme_code_copy" value="true" />
</div>



<body>
<aside class="nav">
    <div class="nav-left">
        <a href="/"
   class="avatar_target">
    <img class="avatar"
         src="/img/myself.png"/>
</a>
<div class="author">
    <span>zxy</span>
</div>

<div class="icon">
    
        
            <a title="github"
               href="https://github.com/zhengxinyao"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-github"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="linkedin"
               href="https://www.linkedin.com/in/%E6%98%95%E7%91%B6-%E9%83%91-956a732b5/"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-linkedin"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="zhihu"
               href="https://www.zhihu.com/people/destiny-44-90-76"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-zhihu"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="csdn"
               href="https://blog.csdn.net/qq_43543209?spm=1010.2135.3001.5343"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-csdn"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="email"
               href="mailto:1601835186@qq.com"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-email"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="qq"
               href="http://wpa.qq.com/msgrd?v=3&uin=1601835186&site=qq&menu=yes"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-qq"></use>
                    </svg>
                
            </a>
        
    
</div>





<ul>
    <li>
        <div class="all active" data-rel="全部文章">全部文章
            
                <small>(30)</small>
            
        </div>
    </li>
    
        
            
                
    <li>
        <div data-rel="论文记录">
            
            论文记录
            <small>(11)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="知识总结">
            
            知识总结
            <small>(17)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="论文写作">
            
            论文写作
            <small>(1)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="阅读分享">
            
            阅读分享
            <small>(1)</small>
        </div>
        
    </li>

            
        
    
</ul>
<div class="left-bottom">
    <div class="menus">
        
            
            
            
    </div>
    <div>
        
        
    </div>
</div>
<input type="hidden" id="yelog_site_posts_number" value="30">

<div style="display: none">
    <span id="busuanzi_value_site_uv"></span>
    <span id="busuanzi_value_site_pv"></span>
</div>

    </div>
    <div class="nav-right">
        <div class="friends-area">
    <div class="friends-title">
        友情链接
        <i class="iconfont icon-left"></i>
    </div>
    <div class="friends-content">
        <ul>
            
            <li><a target="_blank" href="http://yelog.org/">叶落阁</a></li>
            
        </ul>
    </div>
</div>
        <div class="title-list">
    <div class="right-top">
        <div id="default-panel">
            <i class="iconfont icon-search" data-title="搜索 快捷键 i"></i>
            <div class="right-title">全部文章</div>
            <i class="iconfont icon-file-tree" data-title="切换到大纲视图 快捷键 w"></i>
        </div>
        <div id="search-panel">
            <i class="iconfont icon-left" data-title="返回"></i>
            <input id="local-search-input" autocomplete="off"/>
            <label class="border-line" for="input"></label>
            <i class="iconfont icon-case-sensitive" data-title="大小写敏感"></i>
            <i class="iconfont icon-tag" data-title="标签"></i>
        </div>
        <div id="outline-panel" style="display: none">
            <div class="right-title">大纲</div>
            <i class="iconfont icon-list" data-title="切换到文章列表"></i>
        </div>
    </div>

    <div class="tags-list">
    <input id="tag-search" />
    <div class="tag-wrapper">
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>安全</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>侧信道</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>动态缓存划分</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>多租户调度</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>分组加密</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>共享内存</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>加速器</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>架构</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>架构设计</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>论文</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>内存安全</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>内存保护</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>虚拟化</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>云安全</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>AI</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>AI加速器</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>AMD SEV</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>AMD SEV- SNP</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>AMD SEV-SNP</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>ARM CCA</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>GPU</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Intel SGX</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Intel TDX</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>LLM</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>NVM</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>PENGLAI</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>TEE</a>
            </li>
        
    </div>

</div>

    
    <nav id="title-list-nav">
        
        
        <a  class="全部文章 知识总结 "
           href="/2024/02/27/%E3%80%90LLM%E5%AE%89%E5%85%A8%E3%80%91LLM%E7%9A%84%E9%9A%90%E7%A7%81%E5%92%8C%E5%AE%89%E5%85%A8/"
           data-tag="LLM,安全"
           data-author="" >
            <span class="post-title" title="【LLM安全】PERSONAL LLM AGENTS的隐私和安全">【LLM安全】PERSONAL LLM AGENTS的隐私和安全</span>
            <span class="post-date" title="2024-02-27 11:03:20">2024/02/27</span>
        </a>
        
        
        <a  class="全部文章 论文写作 "
           href="/2024/02/27/LLM-and-Security/"
           data-tag="LLM,安全"
           data-author="" >
            <span class="post-title" title="LLM and Security">LLM and Security</span>
            <span class="post-date" title="2024-02-27 09:57:23">2024/02/27</span>
        </a>
        
        
        <a  class="全部文章 阅读分享 "
           href="/2024/02/26/%E9%80%BB%E8%BE%91%E6%96%B0%E5%BC%95-%E6%80%8E%E4%B9%88%E5%88%A4%E5%88%AB%E6%98%AF%E9%9D%9E%EF%BC%88%E6%AE%B7%E6%B5%B7%E5%85%89%EF%BC%89/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="逻辑新引 怎么判别是非（殷海光）">逻辑新引 怎么判别是非（殷海光）</span>
            <span class="post-date" title="2024-02-26 21:53:30">2024/02/26</span>
        </a>
        
        
        <a  class="全部文章 论文记录 "
           href="/2024/02/26/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91A-Survey-on-Large-Language-Model-LLM-Security-and-Privacy-The-Good-the-Bad-and-the-Ugly%EF%BC%88%E7%BB%BC%E8%BF%B0%EF%BC%89/"
           data-tag="LLM,安全"
           data-author="" >
            <span class="post-title" title="【论文】A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly（综述）
【论文】A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly（综述）">【论文】A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly（综述）
【论文】A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly（综述）</span>
            <span class="post-date" title="2024-02-26 20:29:06">2024/02/26</span>
        </a>
        
        
        <a  class="全部文章 知识总结 "
           href="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91SRAM%E7%9A%84%E5%AE%89%E5%85%A8%E6%80%A7/"
           data-tag="安全,架构"
           data-author="" >
            <span class="post-title" title="【架构】SRAM的安全性">【架构】SRAM的安全性</span>
            <span class="post-date" title="2024-02-25 22:55:54">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 知识总结 "
           href="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91%E9%9D%A2%E5%90%91%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-%EF%BC%88AI%EF%BC%89-%E7%9A%84%E7%A1%AC%E4%BB%B6%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7/"
           data-tag="安全,架构,AI,加速器"
           data-author="" >
            <span class="post-title" title="【架构】面向人工智能 （AI） 的硬件的可靠性">【架构】面向人工智能 （AI） 的硬件的可靠性</span>
            <span class="post-date" title="2024-02-25 22:33:18">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 知识总结 "
           href="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/"
           data-tag="GPU,架构"
           data-author="" >
            <span class="post-title" title="【架构】GPU架构总结">【架构】GPU架构总结</span>
            <span class="post-date" title="2024-02-25 20:52:00">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 知识总结 "
           href="/2024/02/25/%E3%80%90%E5%AE%89%E5%85%A8%E3%80%91%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E7%BB%BC%E8%BF%B0/"
           data-tag="LLM,安全"
           data-author="" >
            <span class="post-title" title="【安全】大模型安全综述">【安全】大模型安全综述</span>
            <span class="post-date" title="2024-02-25 20:28:32">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 论文记录 "
           href="/2024/02/25/%E3%80%90TEE%E8%AE%BA%E6%96%87%E3%80%91ProMT-Optimizing-Integrity-Tree-Updates-for-Write-Intensive-Pages-in-Secure-NVMs/"
           data-tag="NVM,内存安全"
           data-author="" >
            <span class="post-title" title="【TEE论文】ProMT: Optimizing Integrity Tree Updates for Write-Intensive Pages in Secure NVMs">【TEE论文】ProMT: Optimizing Integrity Tree Updates for Write-Intensive Pages in Secure NVMs</span>
            <span class="post-date" title="2024-02-25 20:27:27">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 知识总结 "
           href="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E8%99%9A%E6%8B%9F%E5%8C%96/"
           data-tag="GPU,虚拟化"
           data-author="" >
            <span class="post-title" title="【架构】GPU虚拟化">【架构】GPU虚拟化</span>
            <span class="post-date" title="2024-02-25 20:26:11">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 知识总结 "
           href="/2024/02/25/%E3%80%90%E4%BA%91%E5%AE%89%E5%85%A8%E3%80%91%E4%BC%A0%E8%BE%93%E5%B1%82%E5%AE%89%E5%85%A8%E6%80%A7%EF%BC%88TLS%EF%BC%89%E5%A4%A7%E6%B1%87%E6%80%BB/"
           data-tag="云安全"
           data-author="" >
            <span class="post-title" title="【云安全】传输层安全性（TLS）大汇总">【云安全】传输层安全性（TLS）大汇总</span>
            <span class="post-date" title="2024-02-25 20:22:53">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 论文记录 "
           href="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E8%AE%BA%E6%96%87%E3%80%91VELTAIR-Towards-High-Performance-Multi-tenant-Deep-Learning-Services-via-Adaptive-Compilation/"
           data-tag="架构,多租户调度"
           data-author="" >
            <span class="post-title" title="【架构论文】VELTAIR: Towards High-Performance Multi-tenant Deep Learning Services via Adaptive Compilation">【架构论文】VELTAIR: Towards High-Performance Multi-tenant Deep Learning Services via Adaptive Compilation</span>
            <span class="post-date" title="2024-02-25 20:21:48">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 论文记录 "
           href="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E8%AE%BA%E6%96%87%E3%80%91Composable-Cachelets-Protecting-Enclaves-from-Cache-Side-Channel-Attacks%EF%BC%882022USENIX-Security%EF%BC%89/"
           data-tag="TEE,架构,侧信道"
           data-author="" >
            <span class="post-title" title="【架构论文】Composable Cachelets: Protecting Enclaves from Cache Side-Channel Attacks（2022USENIX Security）">【架构论文】Composable Cachelets: Protecting Enclaves from Cache Side-Channel Attacks（2022USENIX Security）</span>
            <span class="post-date" title="2024-02-25 20:19:18">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 论文记录 "
           href="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E8%AE%BA%E6%96%87%E3%80%91SecDCP-Secure-dynamic-cache-partitioning-for-efficient-timing-channel-protection%EF%BC%882016-DAC%EF%BC%89/"
           data-tag="论文,动态缓存划分"
           data-author="" >
            <span class="post-title" title="【架构论文】SecDCP: Secure dynamic cache partitioning for efficient timing channel protection（2016 DAC）">【架构论文】SecDCP: Secure dynamic cache partitioning for efficient timing channel protection（2016 DAC）</span>
            <span class="post-date" title="2024-02-25 20:17:52">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 论文记录 "
           href="/2024/02/25/%E3%80%90TEE%E8%AE%BA%E6%96%87%E3%80%91Reusable-Enclaves-for-Confidential-Serverless-Computing%EF%BC%88usenixsecurity23%EF%BC%89/"
           data-tag="TEE,论文"
           data-author="" >
            <span class="post-title" title="【TEE论文】Reusable Enclaves for Confidential Serverless Computing（usenixsecurity23）">【TEE论文】Reusable Enclaves for Confidential Serverless Computing（usenixsecurity23）</span>
            <span class="post-date" title="2024-02-25 20:14:26">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 论文记录 "
           href="/2024/02/25/%E3%80%90TEE%E8%AE%BA%E6%96%87%E3%80%91Confidential-Serverless-Made-Efficient-with-Plug-In-Enclaves-%EF%BC%882021-ISCA%EF%BC%89/"
           data-tag="TEE,论文,共享内存"
           data-author="" >
            <span class="post-title" title="【TEE论文】Confidential Serverless Made Efficient with Plug-In Enclaves （2021 ISCA）">【TEE论文】Confidential Serverless Made Efficient with Plug-In Enclaves （2021 ISCA）</span>
            <span class="post-date" title="2024-02-25 20:12:45">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 论文记录 "
           href="/2024/02/25/%E3%80%90TEE%E8%AE%BA%E6%96%87%E3%80%91Trust-Beyond-Border-Lightweight-Verifiable-User-Isolation-for-Protecting-In-Enclave-Service/"
           data-tag="TEE,论文"
           data-author="" >
            <span class="post-title" title="【TEE论文】Trust Beyond Border: Lightweight, Verifiable User Isolation for Protecting In-Enclave Service">【TEE论文】Trust Beyond Border: Lightweight, Verifiable User Isolation for Protecting In-Enclave Service</span>
            <span class="post-date" title="2024-02-25 20:11:52">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 论文记录 "
           href="/2024/02/25/%E3%80%90TEE%E8%AE%BA%E6%96%87%E3%80%91-HETEE-Enabling-rack-scale-confidential-computing-using-heterogeneous-TEE-2020-SP/"
           data-tag="TEE,论文"
           data-author="" >
            <span class="post-title" title="【TEE论文】(HETEE)Enabling rack-scale confidential computing using heterogeneous TEE(2020 SP)">【TEE论文】(HETEE)Enabling rack-scale confidential computing using heterogeneous TEE(2020 SP)</span>
            <span class="post-date" title="2024-02-25 20:08:42">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 论文记录 "
           href="/2024/02/25/%E3%80%90TEE%E8%AE%BA%E6%96%87%E3%80%91HyperEnclave-An-Open-and-Cross-platform-Trusted-Execution-Environment%EF%BC%88USENIX-ATC-2022%EF%BC%89/"
           data-tag="TEE,论文"
           data-author="" >
            <span class="post-title" title="【TEE论文】HyperEnclave: An Open and Cross-platform Trusted Execution Environment（USENIX ATC 2022）">【TEE论文】HyperEnclave: An Open and Cross-platform Trusted Execution Environment（USENIX ATC 2022）</span>
            <span class="post-date" title="2024-02-25 20:07:36">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 知识总结 "
           href="/2024/02/25/%E3%80%90TEE%E3%80%91%E7%89%87%E5%A4%96%E5%86%85%E5%AD%98%E4%BF%9D%E6%8A%A4%EF%BC%9AAES%E5%88%86%E7%BB%84%E7%AE%97%E6%B3%95-MAC%E5%AE%8C%E6%95%B4%E6%80%A7%E9%AA%8C%E8%AF%81/"
           data-tag="TEE,内存保护,分组加密"
           data-author="" >
            <span class="post-title" title="【TEE】片外内存保护：AES分组算法+MAC完整性验证">【TEE】片外内存保护：AES分组算法+MAC完整性验证</span>
            <span class="post-date" title="2024-02-25 20:05:04">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 知识总结 "
           href="/2024/02/25/%E3%80%90TEE%E3%80%91Intel-SGX%E7%9A%84%E4%B8%8D%E8%B6%B3%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"
           data-tag="TEE,Intel SGX"
           data-author="" >
            <span class="post-title" title="【TEE】Intel SGX的不足和解决方案">【TEE】Intel SGX的不足和解决方案</span>
            <span class="post-date" title="2024-02-25 19:59:35">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 知识总结 "
           href="/2024/02/25/%E3%80%90TEE%E3%80%91Intel%E5%8F%AF%E4%BF%A1%E6%89%A7%E8%A1%8C%E7%8E%AF%E5%A2%83%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"
           data-tag="TEE,Intel TDX,Intel SGX"
           data-author="" >
            <span class="post-title" title="【TEE】Intel可信执行环境的前世今生">【TEE】Intel可信执行环境的前世今生</span>
            <span class="post-date" title="2024-02-25 19:54:18">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 知识总结 "
           href="/2024/02/25/%E3%80%90TEE%E3%80%91%E5%8F%AF%E4%BF%A1%E6%89%A7%E8%A1%8C%E7%8E%AF%E5%A2%83%E4%BF%9D%E9%9A%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/"
           data-tag="LLM,TEE"
           data-author="" >
            <span class="post-title" title="【TEE】可信执行环境保障大模型安全">【TEE】可信执行环境保障大模型安全</span>
            <span class="post-date" title="2024-02-25 19:52:39">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 知识总结 "
           href="/2024/02/25/%E3%80%90TEE%E3%80%91PENGLAI-TEE/"
           data-tag="TEE,PENGLAI"
           data-author="" >
            <span class="post-title" title="【TEE】PENGLAI TEE">【TEE】PENGLAI TEE</span>
            <span class="post-date" title="2024-02-25 19:51:30">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 知识总结 "
           href="/2024/02/25/%E3%80%90TEE%E3%80%91AMD-SEV-SNP%E5%92%8CIntel-TDX%E7%9A%84%E6%A6%82%E8%BF%B0/"
           data-tag="TEE,AMD SEV- SNP,Intel TDX"
           data-author="" >
            <span class="post-title" title="【TEE】AMD SEV- SNP和Intel TDX的概述">【TEE】AMD SEV- SNP和Intel TDX的概述</span>
            <span class="post-date" title="2024-02-25 19:36:13">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 知识总结 "
           href="/2024/02/25/%E3%80%90TEE%E3%80%91ARM-CCA-%E5%8F%AF%E4%BF%A1%E8%AE%A1%E7%AE%97%E6%9E%B6%E6%9E%84/"
           data-tag="TEE,ARM CCA"
           data-author="" >
            <span class="post-title" title="【TEE】ARM CCA 可信计算架构">【TEE】ARM CCA 可信计算架构</span>
            <span class="post-date" title="2024-02-25 19:24:38">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 知识总结 "
           href="/2024/02/25/%E3%80%90TEE%E3%80%91%E3%80%90AMD-SEV-SNP-%E7%99%BD%E7%9A%AE%E4%B9%A6%E3%80%91%E9%80%9A%E8%BF%87%E5%AE%8C%E6%95%B4%E6%80%A7%E4%BF%9D%E6%8A%A4%E5%8A%A0%E5%BC%BAVM%E9%9A%94%E7%A6%BB/"
           data-tag="TEE,AMD SEV-SNP"
           data-author="" >
            <span class="post-title" title="【TEE】【AMD SEV-SNP 白皮书】通过完整性保护加强VM隔离">【TEE】【AMD SEV-SNP 白皮书】通过完整性保护加强VM隔离</span>
            <span class="post-date" title="2024-02-25 19:11:12">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 知识总结 "
           href="/2024/02/25/%E3%80%90TEE%E3%80%91%E3%80%90AMD-SEV%E5%86%85%E5%AD%98%E5%8A%A0%E5%AF%86%E3%80%91-%E7%99%BD%E7%9A%AE%E4%B9%A6/"
           data-tag="TEE,AMD SEV"
           data-author="" >
            <span class="post-title" title="【TEE】【AMD SEV内存加密】 白皮书">【TEE】【AMD SEV内存加密】 白皮书</span>
            <span class="post-date" title="2024-02-25 19:05:02">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 论文记录 "
           href="/2024/02/25/%E3%80%90TEE%E8%AE%BA%E6%96%87%E3%80%91Confidential-Computing-within-an-AI-Accelerator/"
           data-tag="TEE,论文,AI加速器,架构设计"
           data-author="" >
            <span class="post-title" title="【TEE论文】Confidential Computing within an AI Accelerator">【TEE论文】Confidential Computing within an AI Accelerator</span>
            <span class="post-date" title="2024-02-25 18:53:04">2024/02/25</span>
        </a>
        
        
        <a  class="全部文章 知识总结 "
           href="/2024/02/25/%E3%80%90TEE%E3%80%91%E5%8F%AF%E4%BF%A1%E6%89%A7%E8%A1%8C%E7%8E%AF%E5%A2%83%E4%B8%9A%E7%95%8C%E8%B5%84%E6%96%99/"
           data-tag="TEE"
           data-author="" >
            <span class="post-title" title="【TEE】可信执行环境业界资料">【TEE】可信执行环境业界资料</span>
            <span class="post-date" title="2024-02-25 18:31:25">2024/02/25</span>
        </a>
        
        <div id="no-item-tips">

        </div>
    </nav>
    <div id="outline-list">
    </div>
</div>

    </div>
    <div class="hide-list">
        <div class="semicircle" data-title="切换全屏 快捷键 s">
            <div class="brackets first"><</div>
            <div class="brackets">&gt;</div>
        </div>
    </div>
</aside>
<div id="post">
    <div class="pjax">
        <article id="post-【架构】GPU架构总结" class="article article-type-post" itemscope itemprop="blogPost">
    
        <h1 class="article-title">【架构】GPU架构总结</h1>
    
    <div class="article-meta">
        
        
        
        <span class="book">
            <i class="iconfont icon-category"></i>
            
            
            <a  data-rel="知识总结">知识总结</a>
            
        </span>
        
        
        <span class="tag">
            <i class="iconfont icon-tag"></i>
            
            <a class="color4">GPU</a>
            
            <a class="color3">架构</a>
            
        </span>
        
    </div>
    <div class="article-meta">
        
            发布时间 : <time class="date" title='最后更新: 2024-02-25 22:28:42'>2024-02-25 20:52</time>
        
    </div>
    <div class="article-meta">
        
        
        <span id="busuanzi_container_page_pv">
            阅读 :<span id="busuanzi_value_page_pv">
                <span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </span>
        </span>
        
        
    </div>
    
    <div class="toc-ref">
    
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#GPU%E6%9E%B6%E6%9E%84"><span class="toc-text">GPU架构</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#GPU%E6%B8%B2%E6%9F%93"><span class="toc-text">GPU渲染</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E6%9E%B6%E6%9E%84"><span class="toc-text">内存架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Streaming-Multiprocessor-SM"><span class="toc-text">Streaming Multiprocessor(SM)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CUDA-Core"><span class="toc-text">CUDA Core</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tensor-Core"><span class="toc-text">Tensor Core</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RT-Core"><span class="toc-text">RT Core</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CPU-GPU%E5%BC%82%E6%9E%84%E7%B3%BB%E7%BB%9F"><span class="toc-text">CPU-GPU异构系统</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GPU%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E6%A8%A1%E5%9E%8B"><span class="toc-text">GPU资源管理模型</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#GPU%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B"><span class="toc-text">GPU架构演进</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#G80-%E6%9E%B6%E6%9E%84"><span class="toc-text">G80 架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Fermi-%E6%9E%B6%E6%9E%84"><span class="toc-text">Fermi 架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Maxwell%E6%9E%B6%E6%9E%84"><span class="toc-text">Maxwell架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tesla%E6%9E%B6%E6%9E%84"><span class="toc-text">Tesla架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pascal%E6%9E%B6%E6%9E%84"><span class="toc-text">Pascal架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Volta-%E6%9E%B6%E6%9E%84"><span class="toc-text">Volta 架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pascal%E6%9E%B6%E6%9E%84-1"><span class="toc-text">Pascal架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Volta-%E6%9E%B6%E6%9E%84-1"><span class="toc-text">Volta 架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Turing%E6%9E%B6%E6%9E%84"><span class="toc-text">Turing架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ampere-%E6%9E%B6%E6%9E%84"><span class="toc-text">Ampere 架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hopper%E6%9E%B6%E6%9E%84"><span class="toc-text">Hopper架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GPU%E7%9A%84%E6%9C%AA%E6%9D%A5"><span class="toc-text">GPU的未来</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-text">参考文献</span></a></li></ol>
    
<style>
    .left-col .switch-btn,
    .left-col .switch-area {
        display: none;
    }
    .toc-level-3 i,
    .toc-level-3 ol {
        display: none !important;
    }
</style>
</div>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><div class='inner-toc'><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#GPU%E6%9E%B6%E6%9E%84"><span class="toc-text">GPU架构</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#GPU%E6%B8%B2%E6%9F%93"><span class="toc-text">GPU渲染</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E6%9E%B6%E6%9E%84"><span class="toc-text">内存架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Streaming-Multiprocessor-SM"><span class="toc-text">Streaming Multiprocessor(SM)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CUDA-Core"><span class="toc-text">CUDA Core</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tensor-Core"><span class="toc-text">Tensor Core</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RT-Core"><span class="toc-text">RT Core</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CPU-GPU%E5%BC%82%E6%9E%84%E7%B3%BB%E7%BB%9F"><span class="toc-text">CPU-GPU异构系统</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GPU%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E6%A8%A1%E5%9E%8B"><span class="toc-text">GPU资源管理模型</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#GPU%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B"><span class="toc-text">GPU架构演进</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#G80-%E6%9E%B6%E6%9E%84"><span class="toc-text">G80 架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Fermi-%E6%9E%B6%E6%9E%84"><span class="toc-text">Fermi 架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Maxwell%E6%9E%B6%E6%9E%84"><span class="toc-text">Maxwell架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tesla%E6%9E%B6%E6%9E%84"><span class="toc-text">Tesla架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pascal%E6%9E%B6%E6%9E%84"><span class="toc-text">Pascal架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Volta-%E6%9E%B6%E6%9E%84"><span class="toc-text">Volta 架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pascal%E6%9E%B6%E6%9E%84-1"><span class="toc-text">Pascal架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Volta-%E6%9E%B6%E6%9E%84-1"><span class="toc-text">Volta 架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Turing%E6%9E%B6%E6%9E%84"><span class="toc-text">Turing架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ampere-%E6%9E%B6%E6%9E%84"><span class="toc-text">Ampere 架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hopper%E6%9E%B6%E6%9E%84"><span class="toc-text">Hopper架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GPU%E7%9A%84%E6%9C%AA%E6%9D%A5"><span class="toc-text">GPU的未来</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-text">参考文献</span></a></li></ol></div></p>
<h1 id="GPU架构"><a href="#GPU架构" class="headerlink" title="GPU架构"></a>GPU架构</h1><p>主要组成包括：</p>
<ul>
<li>CUDA 核心：GPU 架构中的主要计算单元，能够处理各种数学和逻辑运算。</li>
<li>内存系统：包括 L1、L2 高速缓存和共享内存等，用于存储数据和指令，以减少 GPU 访问主存的延迟。</li>
<li>高速缓存和缓存行：用于提高 GPU 的内存访问效率。</li>
<li>TPC&#x2F;SM：CUDA 核心的分组结构，一个 TPC 包含两个 SM，每个 SM 都有自己的 CUDA 核心和内存。</li>
<li>Tensor Core（ 2017 年 Volta 架构引入）：Tensor张量核心，用于执行张量计算，支持并行执行FP32与INT32运算。</li>
<li>RT Core（2018 年 Turing 架构引入 ）：光线追踪核心，负责处理光线追踪加速。</li>
<li>NVIDIA GPU 架构还包括内存控制器、高速缓存控制器、CUDA 编译器和驱动程序等其他组件，这些组件与SM 和其他核心组件协同工作，可以实现高效的并行计算和内存访问，提高 GPU 的性能和能效。</li>
</ul>
<h2 id="GPU渲染"><a href="#GPU渲染" class="headerlink" title="GPU渲染"></a>GPU渲染</h2><p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/image-20240225213858155.png"></p>
<p>从Fermi开始NVIDIA使用类似的原理架构，使用一个Giga Thread Engine来管理所有正在进行的工作，GPU被划分成多个GPCs(Graphics Processing Cluster)，每个GPC拥有多个SM（SMX、SMM）和一个光栅化引擎(Raster Engine)，它们其中有很多的连接，最显著的是Crossbar，它可以连接GPCs和其它功能性模块（例如ROP或其他子系统）。</p>
<p>程序员编写的shader是在SM上完成的。每个SM包含许多为线程执行数学运算的Core（核心）。例如，一个线程可以是顶点或像素着色器调用。这些Core和其它单元由Warp Scheduler驱动，Warp Scheduler管理一组32个线程作为Warp（线程束）并将要执行的指令移交给Dispatch Units。</p>
<p>GPU中实际有多少这些单元（每个GPC有多少个SM，多少个GPC ……）取决于芯片配置本身。例如，GM204有4个GPC，每个GPC有4个SM，但Tegra X1有1个GPC和2个SM，它们均采用Maxwell设计。SM设计本身（内核数量，指令单位，调度程序……）也随着时间的推移而发生变化，并帮助使芯片变得如此高效，可以从高端台式机扩展到笔记本电脑移动。</p>
<h2 id="内存架构"><a href="#内存架构" class="headerlink" title="内存架构"></a>内存架构</h2><p>部分架构的GPU与CPU类似，也有多级缓存结构：寄存器、L1缓存、L2缓存、GPU显存、系统显存。但是GPU-style的内存架构ALU定夺，GPU上下文（Context）多，吞吐量高，依赖高带宽与系统内存交换数据。</p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/image-20240225220555264.png"></p>
<p>内存（Memory）是显卡用于存储数据和代码的部分，它可以快速访问大量数据，大大提高了显卡的运算速度。当前英伟达显卡的内存主要分为两种：GDDR5和GDDR6。GDDR5内存具有高带宽、低延迟和低功耗等特点，通常用于较低端的显卡；而GDDR6内存则具有更高的带宽、更低的延迟和更高的功耗，适用于高端游戏等需要更高性能的应用。</p>
<p>显存（Video Memory）是显卡专门用来存储图形数据的部分，它比普通内存更快速，可以更好地支持图形运算。英伟达显卡的显存一般分为两种：GDDR5和GDDR6。GDDR5显存通常用于中低端显卡，而GDDR6显存则主要适用于高端的游戏和图形应用。</p>
<h2 id="Streaming-Multiprocessor-SM"><a href="#Streaming-Multiprocessor-SM" class="headerlink" title="Streaming Multiprocessor(SM)"></a>Streaming Multiprocessor(SM)</h2><p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/image-20240225220638185.png"></p>
<p>SM是 GPU 的基本计算单元，每个 SM 由多个 CUDA 核心、纹理单元、Tensor Core、流控制器和存储器等辅助单元组成，可以同时执行多个计算任务，并具有高度的灵活性和性能。上图为一个SM的构成图，从上到下依次是：</p>
<ul>
<li><strong>PolyMorph Engine</strong>：多边形引擎负责<strong>属性装配（attribute Setup）</strong>、顶点拉取(VertexFetch)、曲面细分、栅格化（这个模块可以理解专门处理顶点相关的东西）。</li>
<li><strong>指令缓存（Instruction Cache）</strong></li>
<li>2个<strong>Warp Schedulers</strong>：这个模块负责warp调度，一个warp由32个线程组成，warp调度器的指令通过Dispatch Units送到Core执行。</li>
<li><strong>指令调度单元(Dispatch Units)</strong> 负责将Warp Schedulers的指令送往Core执行</li>
<li><strong>128KB Register File（寄存器）</strong></li>
<li>16个LD&#x2F;ST（load&#x2F;store）用来加载和存储数据</li>
<li><strong>Core</strong> （Core，也叫<strong>流处理器Stream Processor</strong>）</li>
<li>4个<strong>SFU（Special function units 特殊运算单元）</strong>执行特殊数学运算（sin、cos、log等）</li>
<li><strong>内部链接网络（Interconnect Network）</strong></li>
<li><strong>64KB 共享缓存</strong></li>
<li><strong>全局内存缓存（Uniform Cache）</strong></li>
<li><strong>纹理读取单元(Tex)</strong></li>
</ul>
<h2 id="CUDA-Core"><a href="#CUDA-Core" class="headerlink" title="CUDA Core"></a>CUDA Core</h2><p>CUDA 全称为统一计算设备架构 (Compute Unified Device Architecture) ，是一个并行计算平台，同时也是一个应用程序编程接口 (API)。目的在于让软件开发人员能够更好地控制他们可以使用的物理资源。使用 C 或 C++ 编码的计算机程序员对资源分配有很大的控制权。CUDA 系统极大地促进了 OpenACC 和 OpenCL 等框架的普及和使用。CUDA 核心也是并行处理器，允许不同处理器同时处理数据。这与双核或四核 CPU 类似，只不过 GPU 有数千个 CUDA 核心。</p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/image-20240225220503714.png"></p>
<p>包括控制单元Dispatch Port、Operand Collector，以及浮点计算单元FP Unit、整数计算单元Int Unit，另外还包括计算结果队列。当然还有Compare、Logic、Branch等。相当于微型CPU。</p>
<p>英伟达显卡的多模态构成主要由CUDA、OpenGL及OpenCL等技术构成。</p>
<p>1.CUDA<br>CUDA（Compute Unified Device Architecture）平台是英伟达推出的一种并行计算技术，主要用于加速GPU的计算能力。通过CUDA平台，英伟达显卡可以高效地处理复杂的计算任务，提高计算性能。</p>
<p>2.OpenGL<br>OpenGL是一种开放的图形编程接口，可以在不同的操作系统和硬件平台上运行。英伟达显卡支持OpenGL技术，并可以通过OpenGL实现硬件加速的图形渲染。</p>
<p>3.OpenCL<br>OpenCL是一种开放的并行计算框架，可以同时利用多个处理器来进行运算。英伟达显卡支持OpenCL技术，可以通过OpenCL实现硬件加速的数据处理和计算。</p>
<p><strong>并行计算</strong></p>
<p>CUDA 的巨大优势是任务并行化，这些并行化任务可以使用各种高级语言来执行，例如 C 语言、C++以及 Python，CUDA 是目前最常用的任务加速平台。</p>
<p><strong>应用范围</strong></p>
<p>CUDA 应用范围包括加密哈希、物理引擎、游戏开发等相关项目，在科学行业，在测量、测绘、天气预报和其他等相关项目得到了很大改善和简化。</p>
<p>CUDA 还可以对有风险的金融操作进行预测，将效率加快至少十八倍或更多。其他例子包括 Tesla GPU 在云计算和其他需要强大工作能力的计算系统中广受好评。CUDA 还允许自动驾驶车辆简单高效地运行，能够进行其他系统无法完成的实时计算。</p>
<h2 id="Tensor-Core"><a href="#Tensor-Core" class="headerlink" title="Tensor Core"></a>Tensor Core</h2><p>CUDA 核心足以满足计算工作负载，但 Tensor Core 的速度明显更快。CUDA 核心每个时间周期只能执行一项操作，但 Tensor 核心可以处理多项操作，从而带来令人难以置信的性能提升。从根本意义上来说，Tensor Core 所做的就是提高矩阵乘法的速度。</p>
<p>计算速度的提升确实是以准确性为代价的，从这点上来说 CUDA 核心的准确度要高得多。但是在训练机器学习模型时，Tensor Core 在计算速度和总体成本方面要有效得多。</p>
<p>CUDA Core 专门处理图形工作负载，Tensor Core 更擅长处理数字工作负载。</p>
<h2 id="RT-Core"><a href="#RT-Core" class="headerlink" title="RT Core"></a>RT Core</h2><p>2018 年 NVIDIA 发布了新一代的旗舰显卡 RTX 2080，搭载了全新的 Turing（图灵）架构。全新的架构也同时添加了名为 RT Core 的计算单元。该计算单元的目的是为了让 GPU 拥有实时光线追踪的能力，一种可以让画面更换新的渲染演算法。</p>
<p>光线追踪（Ray Tracing）的原理是从用户端为起点，寻找光线反射和折射的路径并算出用户会看到的物体颜色及亮度。</p>
<h2 id="CPU-GPU异构系统"><a href="#CPU-GPU异构系统" class="headerlink" title="CPU-GPU异构系统"></a>CPU-GPU异构系统</h2><p>根据CPU和GPU是否共享内存，可分为两种类型的CPU-GPU架构：</p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/image-20240225214430899.png"></p>
<p>上图左是分离式架构，CPU和GPU各自有独立的缓存和内存，它们通过PCI-e等总线通讯。这种结构的缺点在于 PCI-e 相对于两者具有低带宽和高延迟，数据的传输成了其中的性能瓶颈。目前使用非常广泛，如PC、智能手机等。</p>
<p>上图右是耦合式架构，CPU 和 GPU 共享内存和缓存。AMD 的 APU 采用的就是这种结构，目前主要使用在游戏主机中，如 PS4。</p>
<p>在存储管理方面，分离式结构中 CPU 和 GPU 各自拥有独立的内存，两者共享一套虚拟地址空间，必要时会进行内存拷贝。对于耦合式结构，GPU 没有独立的内存，与 GPU 共享系统内存，由 MMU 进行存储管理。</p>
<h2 id="GPU资源管理模型"><a href="#GPU资源管理模型" class="headerlink" title="GPU资源管理模型"></a><strong>GPU资源管理模型</strong></h2><p>下图是分离式架构的资源管理模型：</p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/1617944-20190906001903861-1080252910.png"></p>
<ul>
<li><p><strong>MMIO（Memory Mapped IO）</strong></p>
<ul>
<li>CPU与GPU的交流就是通过MMIO进行的。CPU 通过 MMIO 访问 GPU 的寄存器状态。</li>
<li>DMA传输大量的数据就是通过MMIO进行命令控制的。</li>
<li>I&#x2F;O端口可用于间接访问MMIO区域，像Nouveau等开源软件从来不访问它。</li>
</ul>
</li>
<li><p><strong>GPU Context</strong></p>
<ul>
<li>GPU Context代表了GPU计算的状态。</li>
<li>在GPU中拥有自己的虚拟地址。</li>
<li>GPU 中可以并存多个活跃态下的Context。</li>
</ul>
</li>
<li><p><strong>GPU Channel</strong></p>
<ul>
<li>任何命令都是由CPU发出。</li>
<li>命令流（command stream）被提交到硬件单元，也就是GPU Channel。</li>
<li>每个GPU Channel关联一个context，而一个GPU Context可以有多个GPU channel。</li>
<li>每个GPU Context 包含相关channel的 GPU Channel Descriptors ， 每个 Descriptor 都是 GPU 内存中的一个对象。</li>
<li>每个 GPU Channel Descriptor 存储了 Channel 的设置，其中就包括 Page Table 。</li>
<li>每个 GPU Channel 在GPU内存中分配了唯一的命令缓存，这通过MMIO对CPU可见。</li>
<li>GPU Context Switching 和命令执行都在GPU硬件内部调度。</li>
</ul>
</li>
<li><p><strong>GPU Page Table</strong></p>
<ul>
<li>GPU Context在虚拟基地空间由Page Table隔离其它的Context 。</li>
<li>GPU Page Table隔离CPU Page Table，位于GPU内存中。</li>
<li>GPU Page Table的物理地址位于 GPU Channel Descriptor中。</li>
<li>GPU Page Table不仅仅将 GPU虚拟地址转换成GPU内存的物理地址，也可以转换成CPU的物理地址。因此，GPU Page Table可以将GPU虚拟地址和CPU内存地址统一到GPU统一虚拟地址空间来。</li>
</ul>
</li>
<li><p><strong>PCI-e BAR</strong></p>
<ul>
<li>GPU 设备通过PCI-e总线接入到主机上。 Base Address Registers(BARs) 是 MMIO的窗口，在GPU启动时候配置。</li>
<li>GPU的控制寄存器和内存都映射到了BARs中。</li>
<li>GPU设备内存通过映射的MMIO窗口去配置GPU和访问GPU内存。</li>
</ul>
</li>
<li><p><strong>PFIFO Engine</strong></p>
<ul>
<li>PFIFO是GPU命令提交通过的一个特殊的部件。</li>
<li>PFIFO维护了一些独立命令队列，也就是Channel。</li>
<li>此命令队列是Ring Buffer，有PUT和GET的指针。</li>
<li>所有访问Channel控制区域的执行指令都被PFIFO 拦截下来。</li>
<li>GPU驱动使用Channel Descriptor来存储相关的Channel设定。</li>
<li>PFIFO将读取的命令转交给PGRAPH Engine。</li>
</ul>
</li>
<li><p><strong>BO</strong></p>
<ul>
<li><p>Buffer Object (BO)，内存的一块(Block)，能够用于存储纹理（Texture）、渲染目标（Render Target）、着色代码（shader code）等等。</p>
</li>
<li><p>Nouveau和Gdev经常使用BO。</p>
<blockquote>
<p>Nouveau是一个自由及开放源代码显卡驱动程序，是为NVidia的显卡所编写。</p>
<p>Gdev是一套丰富的开源软件，用于NVIDIA的GPGPU技术，包括设备驱动程序。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<p>更多详细可以阅读论文：<a target="_blank" rel="noopener" href="http://www.ertl.jp/~shinpei/papers/icpads13.pdf">Data Transfer Matters for GPU Computing</a>。</p>
<h1 id="GPU架构演进"><a href="#GPU架构演进" class="headerlink" title="GPU架构演进"></a>GPU架构演进</h1><p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/image-20240225213457282.png"></p>
<h2 id="G80-架构"><a href="#G80-架构" class="headerlink" title="G80 架构"></a>G80 架构</h2><p>英伟达第一个 GPU 架构，采用了 MIMD（多指令流多数据流）标量架构，拥有 128 个 SP（流处理器），核心频率范围从 250MHz 到 600MHz，搭配 DDR3 显存。该架构是当时最强大的 GPU 之一，但是功耗较高。</p>
<h2 id="Fermi-架构"><a href="#Fermi-架构" class="headerlink" title="Fermi 架构"></a>Fermi 架构</h2><p><a target="_blank" rel="noopener" href="https://www.nvidia.com/content/PDF/fermi_white_papers/NVIDIA_Fermi_Compute_Architecture_Whitepaper.pdf">Fermi架构白皮书</a><br>Fermi 是 Nvidia 在 2010 年发布的架构，引入了很多今天也仍然不过时的概念。英伟达第一个采用 GPU-Direct 技术的 GPU 架构，它拥有 32 个 SM（流多处理器）和 16 个 PolyMorph Engine 阵列。该架构采用了 4 颗芯片的模块化设计，拥有 32 个光栅化处理单元和 16 个纹理单元，搭配 GDDR5 显存。</p>
<p>GPU 通过 Host Interface 读取 CPU 指令，GigaThread Engine 将特定的数据从 Host Memory 中拷贝到内部的 Framebuffer 中。随后 GigaThread Engine 创建并分发多个 Thread Blocks 到多个 SM 上。多个 SM 彼此独立，并独立调度各自的多个 Thread Wraps 到 SM 内的 CUDA Cores 和其他执行单元上执行。</p>
<p>上面这句话有几个概念解释一下：<br>SM: 对应于上图中的 SM 硬件实体，内部有很多的 CUDA Cores；<br>Thread Block: 一个 Thread Block 包含多个线程（比如几百个），多个 Blocks 之间的执行完全独立，硬件可以任意调度多个 Block 间的执行顺序，而 Block 内部的多个线程执行规则由程序员决定，程同时程序员可以决定一共有多少个 Blocks；<br>Thread Warp: 32 个线程为一个 Thread Warp，Warp 的调度有特殊规则</p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/image-20240225210211510.png"></p>
<p>SM 内有 32 个 CUDA Cores，每个 CUDA Core 含有一个 Integer arithmetic logic unit (ALU)和一个 Floating point unit(FPU). 并且提供了对于单精度和双精度浮点数的 FMA 指令。</p>
<p>SM 内还有 16 个 LD&#x2F;ST 单元，也就是 Load&#x2F;Store 单元，支持 16 个线程一起从 Cache&#x2F;DRAM 存取数据。</p>
<p>4 个 SFU，是指 Special Function Unit，用于计算 sin&#x2F;cos 这类特殊指令。每个 SFU 每个时钟周期只能一个线程执行一条指令。而一个 Warp(32 线程)就需要执行 8 个时钟周期。SFU 的流水线是从 Dispatch Unit 解耦的，所以当 SFU 被占用时，Dispatch Unit 会去使用其他的执行单元。</p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/image-20240225210652105.png"></p>
<p>之前一直提到 Warp，但之前只说明了是 32 个线程，我们在这里终于开始详细说明，首先来看 Dual Warp Scheduler 的概览。</p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/image-20240225215646943.png"></p>
<p>在之前的 SM 概览图以及上图里，可以注意到 SM 内有两个 Warp Scheduler 和两个 Dispatch Unit. 这意味着，同一时刻，会并发运行两个 warp，每个 warp 会被分发到一个 Cuda Core Group(16 个 CUDA Core), 或者 16 个 load&#x2F;store 单元，或者 4 个 SFU 上去真正执行，且每次分发只执行 <strong>一条</strong> 指令，而 Warp Scheduler 维护了多个（比如几十个）的 Warp 状态。</p>
<p>这里引入了一个核心的约束，任意时刻，一个 Warp 里的 Thread 都在执行同样的指令，对于程序员来说，观测不到一个 warp 里不同 thread 的不同执行情况。</p>
<p>但是众所周知，不同线程可能会进入不同的分支，这时如何执行一样的指令？</p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/image-20240225215715218.png"></p>
<p>可以看上图，当发生分支时，只会执行进入该分支的线程，如果进入该分支的线程少，则会发生资源浪费。</p>
<p>在 SM 概览图里，我们可以看到 SM 内 64KB 的 On-Chip Memory，其中 48KB 作为 shared memory, 16KB 作为 L1 Cache. 对于 L1 Cache 以及非 On-Chip 的 L2 Cache，其作用与 CPU 多级缓存结构中的 L1&#x2F;L2 Cache 非常接近，而 Shared Memory，则是相比 CPU 的一个大区别。无论是 CPU 还是 GPU 中的 L1&#x2F;L2 Cache，一般意义上都是无法被程序员调度的，而 Shared Memory 设计出来就是让渡给程序员进行调度的片上高速缓存。</p>
<h2 id="Maxwell架构"><a href="#Maxwell架构" class="headerlink" title="Maxwell架构"></a>Maxwell架构</h2><p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/maxwell-compute-architecture">Maxwell架构白皮书</a></p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/image-20240225211108772.png"></p>
<p>Maxwell的 SM 开始做减法了，每个 SM（SMM）中包含：</p>
<ul>
<li>4 个 Warp Scheduler，8 个 Dispatch Unit</li>
<li>128 个 CUDA Core（4 * 32）</li>
<li>32 个 SFU 和 LD&#x2F;ST Unit（4 * 8）</li>
</ul>
<p>这些硬件单元的流水线分布也不再是像 Kepler 那样大锅炖了，而是有点像是把 4 个差不多像是 Fermi 的 SM 拼在一起组成一个 SM：<br>每个 Process Block 中包含的内容也更加的多，每个Process Block里面包含了：</p>
<ul>
<li>1 个 Warp Scheduler 和 2 个 Dispatch Unit</li>
<li>32 个 CUDA Core</li>
<li>8 个 SFU 和 LD&#x2F;ST Unit</li>
</ul>
<h2 id="Tesla架构"><a href="#Tesla架构" class="headerlink" title="Tesla架构"></a>Tesla架构</h2><p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/image-20240225213614483.png"></p>
<p>Tesla微观架构总览图如上。下面将阐述它的特性和概念：</p>
<ul>
<li>拥有7组TPC（Texture&#x2F;Processor Cluster，纹理处理簇）</li>
<li>每个TPC有两组SM（Stream Multiprocessor，流多处理器）</li>
</ul>
<p>每个SM包含：</p>
<ul>
<li>6个SP（Streaming Processor，流处理器）</li>
<li>2个SFU（Special Function Unit，特殊函数单元）</li>
<li>L1缓存、MT Issue（多线程指令获取）、C-Cache（常量缓存）、共享内存</li>
</ul>
<p>除了TPC核心单元，还有与显存、CPU、系统内存交互的各种部件。</p>
<h2 id="Pascal架构"><a href="#Pascal架构" class="headerlink" title="Pascal架构"></a>Pascal架构</h2><p>SM 内部作了进一步的精简，整体思路是 SM 内部包含的东西越来越少，但是总体的片上 SM 数量每一代都在不断增加，每个 SM 中包含：</p>
<ul>
<li>2 个 Warp Scheduler，4 个 Dispatch Unit</li>
<li>64 个 CUDA Core（2 * 32）</li>
<li>32 个双精浮点单元（2 * 16，双精回来了）</li>
<li>16 个 SFU 和 LD&#x2F;ST Unit（2 * 8）<br>一个 SM 里面包含的 Process Block 数量减少到了 2 个，每个 Process Block 内部的结构倒是 Maxwell 差不多：</li>
<li>1 个 Warp Scheduler 和 2 个 Dispatch Unit</li>
<li>32 个 CUDA Core</li>
<li>多了 16 个 DP Unit</li>
<li>8 个 SFU 和 LD&#x2F;ST Unit<br>此外还有一些其它的升级变化：</li>
<li>面向 Deep Learning 做了一些专门的定制（CuDNN 等等库）。</li>
<li>除了 PCIE 以外，P100 还有 NVLink 版，单机卡间通信带宽逆天了，多机之间也能通过 Infiniband 进一步扩展 NVLink（GPUDirect）。</li>
<li>P100 上把 GDDR5 换成了 HBM2，Global Memory 的带宽涨了一个数量级。</li>
<li>16nm FinFET 工艺，性能提升一大截，功耗还能控制住不怎么增加。</li>
<li>Unified Memory，支持把 GPU 的显存和 CPU 的内存统一到一个相同的地址空间，驱动层自己会做好 DtoH 和 HtoD 的内存拷贝，编程模型上更加友好了。</li>
<li>CUDA Core 也有了升级，现在硬件上直接支持 FP16 的半精计算了，半精性能是单精的 2 倍。<br>Volta架构</li>
</ul>
<h2 id="Volta-架构"><a href="#Volta-架构" class="headerlink" title="Volta 架构"></a>Volta 架构</h2><p><a target="_blank" rel="noopener" href="https://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf">Volta白皮书</a><br>采用了全新的设计理念和技术，拥有 256 个 SM 和 32 个 PolyMorph Engine 阵列，每个 SM 都拥有 64 个 CUDA 核心。该架构采用了全新的 Tensor 张量核心、ResNet 和 InceptionV3 加速模块等技术，搭配 GDDR6X 显存。</p>
<p>Maxwell的 SM 开始做减法了，每个 SM（SMM）中包含：</p>
<ul>
<li>4 个 Warp Scheduler，8 个 Dispatch Unit</li>
<li>128 个 CUDA Core（4 * 32）</li>
<li>32 个 SFU 和 LD&#x2F;ST Unit（4 * 8）</li>
</ul>
<p>这些硬件单元的流水线分布也不再是像 Kepler 那样大锅炖了，而是有点像是把 4 个差不多像是 Fermi 的 SM 拼在一起组成一个 SM：<br>每个 Process Block 中包含的内容也更加的多，每个Process Block里面包含了：</p>
<ul>
<li>1 个 Warp Scheduler 和 2 个 Dispatch Unit</li>
<li>32 个 CUDA Core</li>
<li>8 个 SFU 和 LD&#x2F;ST Unit</li>
</ul>
<h2 id="Pascal架构-1"><a href="#Pascal架构-1" class="headerlink" title="Pascal架构"></a>Pascal架构</h2><p>SM 内部作了进一步的精简，整体思路是 SM 内部包含的东西越来越少，但是总体的片上 SM 数量每一代都在不断增加，每个 SM 中包含：</p>
<ul>
<li>2 个 Warp Scheduler，4 个 Dispatch Unit</li>
<li>64 个 CUDA Core（2 * 32）</li>
<li>32 个双精浮点单元（2 * 16，双精回来了）</li>
<li>16 个 SFU 和 LD&#x2F;ST Unit（2 * 8）</li>
</ul>
<p>一个 SM 里面包含的 Process Block 数量减少到了 2 个，每个 Process Block 内部的结构倒是 Maxwell 差不多：</p>
<ul>
<li>1 个 Warp Scheduler 和 2 个 Dispatch Unit</li>
<li>32 个 CUDA Core</li>
<li>多了 16 个 DP Unit</li>
<li>8 个 SFU 和 LD&#x2F;ST Unit</li>
</ul>
<p>此外还有一些其它的升级变化：</p>
<ul>
<li>面向 Deep Learning 做了一些专门的定制（CuDNN 等等库）。</li>
<li>除了 PCIE 以外，P100 还有 NVLink 版，单机卡间通信带宽逆天了，多机之间也能通过 Infiniband 进一步扩展 NVLink（GPUDirect）。</li>
<li>P100 上把 GDDR5 换成了 HBM2，Global Memory 的带宽涨了一个数量级。</li>
<li>16nm FinFET 工艺，性能提升一大截，功耗还能控制住不怎么增加。</li>
<li>Unified Memory，支持把 GPU 的显存和 CPU 的内存统一到一个相同的地址空间，驱动层自己会做好 DtoH 和 HtoD 的内存拷贝，编程模型上更加友好了。</li>
<li>CUDA Core 也有了升级，现在硬件上直接支持 FP16 的半精计算了，半精性能是单精的 2 倍。</li>
</ul>
<h2 id="Volta-架构-1"><a href="#Volta-架构-1" class="headerlink" title="Volta 架构"></a>Volta 架构</h2><p><a target="_blank" rel="noopener" href="https://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf">Volta白皮书</a></p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/image-20240225220024587.png"></p>
<p>2017年。采用了全新的设计理念和技术，拥有 256 个 SM 和 32 个 PolyMorph Engine 阵列，每个 SM 都拥有 64 个 CUDA 核心。该架构采用了全新的 Tensor 张量核心、ResNet 和 InceptionV3 加速模块等技术，搭配 GDDR6X 显存。这个架构可以说是完全以 Deep Learning 为核心了，相比 Pascal 也是一个大版本。<br>和 Pascal 的改变类似，到了 Volta，直接拆了 4 个区块，每个区块多配了一个 L0 指令缓存，而 Shared Memory&#x2F;Register File 这都没有变少，也就和 Pascal 的改变一样，单个线程可使用的资源更多了。单个区块还多个两个名为 Tensor Core 的单元，这就是这个版本的核心了。可以吐槽一下，这个版本又把 L1 和 Shared Memory 合并了。</p>
<p>我们首先看 CUDA Core, 可以看到，原本的 CUDA Core 被拆成了 FP32 Cuda Core 和 INT32 Cuda Core，这意味着可以同时执行 FP32 和 INT32 的操作。</p>
<h2 id="Turing架构"><a href="#Turing架构" class="headerlink" title="Turing架构"></a>Turing架构</h2><p><a target="_blank" rel="noopener" href="https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/technologies/turing-architecture/NVIDIA-Turing-Architecture-Whitepaper.pdf">Turing架构白皮书</a></p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/image-20240225212108966.png"></p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/image-20240225212216439.png"></p>
<p>每个GPC均包含一个专用的光栅化引擎和6个TPC，且每个TPC均包含两个SM。每个SM包含：</p>
<ul>
<li>64个CUDA核心</li>
<li>8个Tensor核心</li>
<li>1个256KB寄存器堆</li>
<li>4个纹理单元以及96KB的L1或共享内存</li>
<li>可根据计算或图形工作负载将这些内存设置为不同容量。每个SM中的全新RT核心处理引擎负责执行光线追踪加速。</li>
</ul>
<p>Turing架构采用全新SM设计，每个TPC均包含两个SM，每个SM共有64个FP32核心和64个INT32核心。Turing SM支持并行执行FP32与INT32运算，每个Turing SM还拥有8个混合精度Turing Tensor核心和1个RT核心。</p>
<h2 id="Ampere-架构"><a href="#Ampere-架构" class="headerlink" title="Ampere 架构"></a>Ampere 架构</h2><p><a target="_blank" rel="noopener" href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/nvidia-ampere-architecture-whitepaper.pdf">Ampere架构白皮书</a><br>代表产品为 GeForce RTX 30 系列。该架构继续优化并行计算能力，并引入了更先进的 GDDR6X 内存技术，大幅提高了内存带宽和性能。相比 Turing 架构，Ampere 架构中的 SM 在 Turing 基础上增加了一倍的 FP32 运算单元，这使得每个 SM 的 FP32 运算单元数量提高了一倍，同时吞吐量也就变为了一倍。此外，安培架构还改进了着色器性能和张量核（Tensor Cores），进一步加速深度学习和人工智能任务的处理速度。</p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/image-20240225212433137.png"></p>
<p>NVIDIA Ampere GA100 GPU架构满配如下：</p>
<ul>
<li>8 GPCs,</li>
<li>8 TPCs&#x2F;GPC, 2 SMs&#x2F;TPC, 16 SMs&#x2F;GPC, 128 SMs per full GPU</li>
<li>64 FP32 CUDA Cores&#x2F;SM, 8192 FP32 CUDA Cores per full GPU</li>
<li>4第三代Tensor Cores&#x2F;SM, 512第三代Tensor Cores per full GPU</li>
<li>6 HBM2 stacks, 12 512bit 内存控制器</li>
</ul>
<p>NVIDIA A100在AI训练（半&#x2F;单精度操作，FP16&#x2F;32）和推理（8位整数操作，INT8）方面，GPU比Volta GPU强大20倍。在高性能计算（双精度运算，FP64）方面，NVIDIA表示GPU的速度将提高2.5倍。</p>
<p>五大突破：</p>
<ul>
<li>NVIDIA Ampere架构 — A100的核心是NVIDIA Ampere GPU架构，其中包含超过540亿个晶体管，使其成为世界上最大的7纳米处理器。</li>
<li>基于TF32的第三代张量核(Tensor Core)： Tensor核心的应用使得GPU更加灵活，更快，更易于使用。TF32包括针对AI的扩展，无需进行任何代码更改即可使FP32精度的AI性能提高20倍。此外， TensorCore 现在支持FP64，相比上一代，HPC应用程序可提供多达2.5倍的计算量。</li>
<li>多实例（Multi-Instance）GPU — MIG是一项新技术功能，可将单个A100GPU划分为多达七个独立的GPU，因此它可以为不同大小的作业提供不同程度的计算，从而提供最佳利用率。</li>
<li>第三代NVIDIA NVLink —使GPU之间的高速连接速度加倍，可在服务器中提供有效的性能扩展。</li>
<li>结构稀疏性—这项新的效率技术利用了AI数学固有的稀疏特性来使性能提高一倍。</li>
</ul>
<p>NVIDIA A100基于7nm Ampere GA100 GPU，具有6912 CUDA内核和432 Tensor Core，540亿个晶体管数，108个流式多处理器。采用第三代NVLINK，GPU和服务器双向带宽为4.8 TB&#x2F;s，GPU间的互连速度为600 GB&#x2F;s。另外，Tesla A100在5120条内存总线上的HBM2内存可达40GB。</p>
<h2 id="Hopper架构"><a href="#Hopper架构" class="headerlink" title="Hopper架构"></a>Hopper架构</h2><p><a target="_blank" rel="noopener" href="https://resources.nvidia.com/en-us-tensor-core">Hopper架构白皮书</a></p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/image-20240225212642414.png"></p>
<p>作为面向专业计算的GPU，H100采用HBM3高带宽显存，NVIDIA将六颗HBM3高带宽显存堆栈在核心两侧。核心内建5120-bit的HBM3显存位宽，英伟达可配置最高80GB显存，SXM5版（HBM3显存）带宽更是达到3TB&#x2F;s，PCIe版本（HBM2e）则是2TB&#x2F;s。</p>
<p>H100的主机接口同样迎来升级，SXM外形的PCB板配备新一代NVLink，拥有900GB&#x2F;s的带宽。面对AIC插卡版本采用PCIe 5.0 x16(拥有128GB&#x2F;s)接口，两者均引入了资源池(resource-pooling)功能，加速GPU之间的数据交换。</p>
<p>虽然H100拥有144组单元，但SXM版也只启用其中的132组单元。PCIe版本更是只有114组，两者的最高频率均为1.8GHz。不仅如此，H100核心的功率高达700W，PCIe版本也达到350W，上一代的A100仅为400W;在提升性能的同时，H100的功耗也在大幅上升。</p>
<h2 id="GPU的未来"><a href="#GPU的未来" class="headerlink" title="GPU的未来"></a>GPU的未来</h2><p>从章节[2.2 GPU历史](#2.2 GPU历史)可以得出一些结论，也可以推测GPU发展的趋势：</p>
<ul>
<li><p><strong>硬件升级</strong>。更多运算单元，更多存储空间，更高并发，更高带宽，更低延时。。。</p>
</li>
<li><p><strong>Tile-Based Rendering的集成</strong>。基于瓦片的渲染可以一定程度降低带宽和提升光照计算效率，目前部分移动端及桌面的GPU已经引入这个技术，未来将有望成为常态。</p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/1617944-20190906002505353-1795972401.png"></p>
</li>
<li><p><strong>3D内存技术</strong>。目前大多数传统的内存是2D的，3D内存则不同，在物理结构上是3D的，类似立方体结构，集成于芯片内。可获得几倍的访问速度和效能比。</p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/1617944-20190906002515798-390893434.png"></p>
</li>
<li><p><strong>GPU愈加可编程化</strong>。GPU天生是并行且相对固定的，未来将会开放越来越多的shader可供编程，而CPU刚好相反，将往并行化发展。也就是说，未来的GPU越来越像CPU，而CPU越来越像GPU。难道它们应验了古语：合久必分，分久必合么？</p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/1617944-20190906002526368-869362108.png"></p>
</li>
<li><p><strong>实时光照追踪的普及</strong>。基于Turing架构的GPU已经加入大量RT Core、HVB、AI降噪等技术，<strong>Hybrid Rendering Pipeline</strong>就是此架构的光线追踪渲染管线，能够同时结合光栅化器、RT Core、Compute Core执行混合渲染：</p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/1617944-20190906002614137-1649844728.png"></p>
<p>Hybrid Rendering Pipeline相当于光线追踪渲染管线和光栅化渲染管线的合体：</p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/1617944-20190906002640206-1719797478.png"></p>
</li>
<li><p><strong>数据并发提升、深度神经网络、GPU计算单元等普及及提升</strong>。</p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/1617944-20190906002651828-1748826144.png"></p>
</li>
<li><p><strong>AI降噪和AI抗锯齿</strong>。AI降噪已经在部分RTX系列的光线追踪版本得到应用，而AI抗锯齿（Super Res）可用于超高分辨率的视频图像抗锯齿：</p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/1617944-20190906002700010-1369006901.png"></p>
</li>
<li><p><strong>基于任务和网格着色器的渲染管线</strong>。基于任务和网格着色器的渲染管线（Graphics Pipeline with Task and Mesh Shaders）与传统的光栅化渲染光线有着很大的差异，它以线程组（Thread Group）、任务着色器（Task shader）和网格着色器（Mesh shader）为基础，形成一种全新的渲染管线：</p>
<p><img src="/2024/02/25/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91GPU%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/1617944-20190906002714352-1153921712.png"></p>
<p>关于此技术的更多详情可阅读：<a target="_blank" rel="noopener" href="https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/technologies/turing-architecture/NVIDIA-Turing-Architecture-Whitepaper.pdf">NVIDIA Turing Architecture Whitepaper</a>。</p>
</li>
<li><p><strong>可变速率着色（Variable Rate Shading）</strong>。可变利率着色技术可判断画面区域的重要性（或由应用程序指定），然后根据画面区域的重要性程度采用不同的着色分辨率精度，可以显著降低功耗，提高着色效率。</p>
</li>
</ul>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000044379561">https://segmentfault.com/a/1190000044379561</a><br>[2] <a target="_blank" rel="noopener" href="https://blog.csdn.net/daijingxin/article/details/115042353">https://blog.csdn.net/daijingxin/article/details/115042353</a><br>[3] <a target="_blank" rel="noopener" href="https://www.cnblogs.com/timlly/p/11471507.html">https://www.cnblogs.com/timlly/p/11471507.html</a><br>[4] <a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1891497">https://cloud.tencent.com/developer/article/1891497</a></p>

      
       <hr><span style="font-style: italic;color: gray;"> 转载请注明来源，欢迎对文章中的引用来源进行考证，欢迎指出任何有错误或不够清晰的表达，可以在下面评论区评论 </span>
    </div>
</article>


<p>
    <a  class="dashang" onclick="dashangToggle()">赏</a>
</p>






    




    </div>
    <div class="copyright">
        <p class="footer-entry">
    ©2016-2020 zxy
</p>
<p class="footer-entry">Built with <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank">3-hexo</a> theme</p>

    </div>
    <div class="full-toc">
        <button class="full" data-title="切换全屏 快捷键 s"><span class="min "></span></button>
<a class="" id="rocket" ></a>

    </div>
</div>

<div class="hide_box" onclick="dashangToggle()"></div>
<div class="shang_box">
    <a class="shang_close"  onclick="dashangToggle()">×</a>
    <div class="shang_tit">
        <p>喜欢就点赞,疼爱就打赏</p>
    </div>
    <div class="shang_payimg">
        <div class="pay_img">
            <img src="/img/alipay.jpg" class="alipay" title="扫码支持">
            <img src="/img/weixin.jpg" class="weixin" title="扫码支持">
        </div>
    </div>
    <div class="shang_payselect">
        <span><label><input type="radio" name="pay" checked value="alipay">支付宝</label></span><span><label><input type="radio" name="pay" value="weixin">微信</label></span>
    </div>
</div>


</body>
<script src="/js/jquery.pjax.js?v=1.1.0" ></script>

<script src="/js/script.js?v=1.1.0" ></script>
<script>
    var img_resize = 'default';
    function initArticle() {
        /*渲染对应的表格样式*/
        
            $("#post .pjax table").addClass("green_title");
        

        /*渲染打赏样式*/
        
        $("input[name=pay]").on("click", function () {
            if($("input[name=pay]:checked").val()=="weixin"){
                $(".shang_box .shang_payimg .pay_img").addClass("weixin_img");
            } else {
                $(".shang_box .shang_payimg .pay_img").removeClass("weixin_img");
            }
        })
        

        /*高亮代码块行号*/
        

        /*访问数量*/
        
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js");
        

        /*代码高亮，行号对齐*/
        $('.pre-numbering').css('line-height',$('.has-numbering').css('line-height'));

        
        
    }

    /*打赏页面隐藏与展示*/
    
    function dashangToggle() {
        $(".shang_box").fadeToggle();
        $(".hide_box").fadeToggle();
    }
    

</script>

<!--加入行号的高亮代码块样式-->

<!--自定义样式设置-->
<style>
    
    
    .nav {
        width: 542px;
    }
    .nav.fullscreen {
        margin-left: -542px;
    }
    .nav-left {
        width: 120px;
    }
    
    
    @media screen and (max-width: 1468px) {
        .nav {
            width: 492px;
        }
        .nav.fullscreen {
            margin-left: -492px;
        }
        .nav-left {
            width: 100px;
        }
    }
    
    
    @media screen and (max-width: 1024px) {
        .nav {
            width: 492px;
            margin-left: -492px
        }
        .nav.fullscreen {
            margin-left: 0;
        }
    }
    
    @media screen and (max-width: 426px) {
        .nav {
            width: 100%;
        }
        .nav-left {
            width: 100%;
        }
    }
    
    
    .nav-right .title-list nav a .post-title, .nav-right .title-list #local-search-result a .post-title {
        color: #383636;
    }
    
    
    .nav-right .title-list nav a .post-date, .nav-right .title-list #local-search-result a .post-date {
        color: #5e5e5f;
    }
    
    
    .nav-right nav a.hover, #local-search-result a.hover{
        background-color: #e2e0e0;
    }
    
    

    /*列表样式*/
    

    /* 背景图样式 */
    
    


    /*引用块样式*/
    

    /*文章列表背景图*/
    

    
</style>







</html>
